{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ55VuvxLStMM/yVmpGaT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timixojo/Timixojo/blob/main/Electricity%20usage%20analysis_7005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPHo8-Ewu4NJ"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ML libraries\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import davies_bouldin_score"
      ],
      "metadata": {
        "id": "r2YLNwfQvP3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Excel file\n",
        "\n",
        "file_path = \"/content/rural_data_with_summary.xlsx\"\n",
        "\n",
        "geo_rural = pd.read_excel(file_path, sheet_name=\"Geo_rural\")\n",
        "hh_rural = pd.read_excel(file_path, sheet_name=\"HH_rural\")\n",
        "apps_rural = pd.read_excel(file_path, sheet_name=\"HHapps_rural\")\n",
        "\n",
        "# Display Data Sheets\n",
        "print(\"Geo Rural\")\n",
        "display(geo_rural)\n",
        "\n",
        "#print(\"Household Rural\")\n",
        "#display(hh_rural)\n",
        "\n",
        "#print(\"Appliance Rural\")\n",
        "display(apps_rural)"
      ],
      "metadata": {
        "id": "mE9jBIP3vYRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning Script\n",
        "\n",
        "# Geo Rural Cleaning\n",
        "\n",
        "# Drop rows with missing essential geographic information\n",
        "geo_rural = geo_rural.dropna(subset=[\"zone\", \"state\", \"eaid\", \"urca_cat\"])\n",
        "\n",
        "# Keep only rows categorized as rural based on proximity to cities/towns\n",
        "rural_values = [\"<1hr to large city\", \"<1hr to int. city\", \"<1hr to small city/town+\"]\n",
        "geo_rural = geo_rural[geo_rural[\"urca_cat\"].isin(rural_values)]\n",
        "\n",
        "# Remove entries with non-positive household size (assuming hhsize should be at least 1)\n",
        "geo_rural = geo_rural[geo_rural[\"hhsize\"] > 0]\n",
        "\n",
        "# Display Cleaned Geo Rural\n",
        "print(\"Cleaned Geo Rural\")\n",
        "display(geo_rural)\n",
        "\n",
        "# Household Rural Cleaning\n",
        "\n",
        "# Keep entries with positive decoded household size (remove zero/negative)\n",
        "hh_rural = hh_rural[hh_rural[\"hhsize_decoded\"] > 0]\n",
        "\n",
        "# Drop rows with missing decoded household income\n",
        "hh_rural = hh_rural.dropna(subset=[\"hhincome_decoded\"])\n",
        "\n",
        "# Remove duplicate household entries based on hhid\n",
        "hh_rural = hh_rural.drop_duplicates(subset=[\"hhid\"])\n",
        "\n",
        "# Display Cleaned Household Rural\n",
        "print(\"Cleaned Household Rural\")\n",
        "display(hh_rural)\n",
        "\n",
        "# Household Appliance Rural Cleaning\n",
        "\n",
        "# Calculate total usage hours by summing q403_2 and q403_3, filling missing values with 0\n",
        "apps_rural[\"usage_hours\"] = apps_rural[[\"q403_2\",\"q403_3\"]].fillna(0).sum(axis=1)\n",
        "\n",
        "# Keep only appliance entries with usage hours greater than 0\n",
        "apps_rural = apps_rural[apps_rural[\"usage_hours\"] > 0]\n",
        "\n",
        "# Keep only appliance entries with realistic usage hours (<= 24)\n",
        "apps_rural = apps_rural[apps_rural[\"usage_hours\"] <= 24]\n",
        "\n",
        "# Drop rows with missing household IDs in the appliance data\n",
        "apps_rural = apps_rural.dropna(subset=[\"hhid\"])\n",
        "\n",
        "# Remove duplicate appliance entries (if any appliance instance is listed more than once for a household)\n",
        "apps_rural = apps_rural.drop_duplicates()\n",
        "\n",
        "# Display Cleaned Household Appliance Rural\n",
        "print(\"Cleaned Household Appliance Rural\")\n",
        "display(apps_rural)\n",
        "\n",
        "# Check unique appliance counts per household after cleaning\n",
        "appliance_counts_after_cleaning = apps_rural.groupby('hhid')['q403'].nunique()"
      ],
      "metadata": {
        "id": "f4JWTv9wSKWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Cleaned Data( Geo Rural, Household Rural and Household Appliance Rural) Files\n",
        "\n",
        "output_file = \"/content/rural_data_cleaned_revised.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
        "    geo_rural.to_excel(writer, sheet_name=\"Geo_rural_cleaned_revised\", index=False)\n",
        "    hh_rural.to_excel(writer, sheet_name=\"HH_rural_cleaned_revised\", index=False)\n",
        "    apps_rural.to_excel(writer, sheet_name=\"HHapps_rural_cleaned_revised\", index=False)\n",
        "\n",
        "print(f\"\\nCleaned data saved to: {output_file}\")"
      ],
      "metadata": {
        "id": "InY67ftsKw1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stat\n",
        "\n",
        "print(\"Unique households (hhid):\", hh_rural[\"hhid\"].nunique())\n",
        "print(\"Unique LGAs:\", hh_rural[\"lga\"].nunique())\n",
        "print(\"Unique States:\", hh_rural[\"state\"].nunique())\n",
        "print(\"Unique Zones:\", hh_rural[\"zone\"].nunique())"
      ],
      "metadata": {
        "id": "rJPawsOkxasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "def show(title, df):\n",
        "    print(f\"\\n{title}\")\n",
        "    display(df)\n",
        "\n",
        "# GEO_RURAL_CLEANED (EDA)\n",
        "\n",
        "# EAIDs per Zone\n",
        "eaid_zone = geo_rural[\"zone\"].value_counts().reset_index()\n",
        "eaid_zone.columns = [\"zone\", \"eaid_count\"]\n",
        "\n",
        "# EAIDs per State\n",
        "eaid_state = geo_rural[\"state\"].value_counts().reset_index()\n",
        "eaid_state.columns = [\"state\", \"eaid_count\"]\n",
        "\n",
        "# EAIDs per Rural Category\n",
        "eaid_urcat = geo_rural[\"urca_cat\"].value_counts().reset_index()\n",
        "eaid_urcat.columns = [\"urca_cat\", \"eaid_count\"]\n",
        "\n",
        "# EAID stats (count/unique/top/freq)\n",
        "eaid_stats = geo_rural[\"eaid\"].describe().to_frame(\"eaid_stats\")\n",
        "\n",
        "# Display\n",
        "print(\"\\neaid_zone:\")\n",
        "display(eaid_zone)\n",
        "\n",
        "print(\"\\neaid_state:\")\n",
        "display(eaid_state)\n",
        "\n",
        "print(\"\\neaid_urcat:\")\n",
        "display(eaid_urcat)\n",
        "\n",
        "print(\"\\neaid_stats:\")\n",
        "display(eaid_stats)\n",
        "\n",
        "# HH_RURAL_CLEANED (EDA)\n",
        "\n",
        "income_top = (hh_rural[\"hhincome_decoded\"]\n",
        "              .value_counts()\n",
        "              .reset_index()\n",
        "              .rename(columns={\"index\":\"income_source\",\"hhincome_decoded\":\"households\"}))\n",
        "\n",
        "hhsize_stats = hh_rural[\"hhsize_decoded\"].describe().to_frame(\"hhsize_stats\")\n",
        "\n",
        "show(\"Income Categories (All, sorted)\", income_top)\n",
        "show(\"Household Size Summary (HH)\", hhsize_stats)\n",
        "\n",
        "# HHAPPS_RURAL_CLEANED (EDA)\n",
        "\n",
        "# Ensure an 'appliance' alias and usage hours column exist (idempotent)\n",
        "if \"appliance\" not in apps_rural.columns:\n",
        "    apps_rural[\"appliance\"] = apps_rural[\"q403\"].astype(str)\n",
        "\n",
        "if \"usage_hours\" not in apps_rural.columns:\n",
        "    apps_rural[\"usage_hours\"] = apps_rural[[\"q403_2\",\"q403_3\"]].fillna(0).sum(axis=1)\n",
        "\n",
        "appliance_top = (apps_rural[\"appliance\"]\n",
        "                 .value_counts()\n",
        "                 .reset_index()\n",
        "                 .rename(columns={\"index\":\"appliance\",\"appliance\":\"count\"}))\n",
        "\n",
        "usage_by_appliance = (apps_rural\n",
        "                      .groupby(\"appliance\", as_index=False)[\"usage_hours\"]\n",
        "                      .mean()\n",
        "                      .sort_values(\"usage_hours\", ascending=False))\n",
        "\n",
        "usage_per_hh = (apps_rural\n",
        "                .groupby(\"hhid\", as_index=False)[\"usage_hours\"]\n",
        "                .sum()\n",
        "                .rename(columns={\"usage_hours\":\"total_usage_hours\"}))\n",
        "\n",
        "usage_per_hh_stats = usage_per_hh[\"total_usage_hours\"].describe().to_frame(\"total_usage_hours_stats\")\n",
        "\n",
        "show(\"Top Appliances (by records)\", appliance_top.head(10))\n",
        "show(\"Average Usage Hours per Appliance\", usage_by_appliance.head(10))\n",
        "show(\"Total Usage Hours per Household (summary)\", usage_per_hh_stats)"
      ],
      "metadata": {
        "id": "Ns1OStqjjLNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA VISUALISATION\n",
        "\n",
        "# GEO_RURAL: EAID distributions\n",
        "\n",
        "# EAIDs per State\n",
        "plt.figure(figsize=(8,4))\n",
        "eaid_state.set_index(\"state\")[\"eaid_count\"].plot(kind=\"bar\")\n",
        "plt.title(\"EAIDs per State\")\n",
        "plt.ylabel(\"Number of EAIDs\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# EAIDs per Zone\n",
        "plt.figure(figsize=(8,4))\n",
        "eaid_zone.set_index(\"zone\")[\"eaid_count\"].plot(kind=\"bar\")\n",
        "plt.title(\"EAIDs per Zone\")\n",
        "plt.ylabel(\"Number of EAIDs\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# EAIDs per Rural Category\n",
        "plt.figure(figsize=(6,6))\n",
        "eaid_urcat.set_index(\"urca_cat\")[\"eaid_count\"].plot(\n",
        "    kind=\"pie\",\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    legend=False\n",
        ")\n",
        "plt.title(\"EAIDs per Rural Category\")\n",
        "plt.ylabel(\"\")  # remove y-label\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# HOUSEHOLDS: Size + Income\n",
        "\n",
        "# Household size distribution\n",
        "plt.figure(figsize=(8,4))\n",
        "hh_rural[\"hhsize_decoded\"].plot(kind=\"hist\", bins=15)\n",
        "plt.title(\"Household Size Distribution\")\n",
        "plt.xlabel(\"Household size\")\n",
        "plt.ylabel(\"HH Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top income sources\n",
        "income_counts = hh_rural[\"hhincome_decoded\"].value_counts().head(10)\n",
        "plt.figure(figsize=(8,4))\n",
        "income_counts.sort_values(ascending=True).plot(kind=\"barh\")\n",
        "plt.title(\"Top Income Sources\")\n",
        "plt.xlabel(\"Number of Households\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# APPLIANCES: Ownership + Usage\n",
        "\n",
        "# Top Appliances\n",
        "appliance_counts = apps_rural[\"q403\"].astype(str).value_counts().head(10)\n",
        "plt.figure(figsize=(8,4))\n",
        "appliance_counts.plot(kind=\"bar\")\n",
        "plt.title(\"Top Appliances\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Average usage hours per appliance\n",
        "usage_by_app = (apps_rural\n",
        "                .assign(appliance=apps_rural[\"q403\"].astype(str))\n",
        "                .groupby(\"appliance\")[\"usage_hours\"].mean()\n",
        "                .sort_values(ascending=False)\n",
        "                .head(10))\n",
        "plt.figure(figsize=(8,4))\n",
        "usage_by_app.sort_values(ascending=True).plot(kind=\"barh\")\n",
        "plt.title(\"Average Usage Hours per Appliance\")\n",
        "plt.xlabel(\"Average Hours per Day\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Load vs Peak (household-level)\n",
        "\n",
        "# Total device-hours per household (sum of all appliances)\n",
        "total_device_hours = (apps_rural.groupby(\"hhid\")[\"usage_hours\"]\n",
        "                      .sum()\n",
        "                      .rename(\"total_device_hours\"))\n",
        "\n",
        "# Peak single-appliance hours per household (max; ≤ 24)\n",
        "peak_single_appliance_hours = (apps_rural.groupby(\"hhid\")[\"usage_hours\"]\n",
        "                               .max()\n",
        "                               .rename(\"peak_single_appliance_hours\"))\n",
        "\n",
        "# Plot: total device-hours (hist; can exceed 24)\n",
        "plt.figure(figsize=(8,4))\n",
        "total_device_hours.plot(kind=\"hist\", bins=20)\n",
        "plt.title(\"Total Device-Hours per Household (Sum across appliances)\")\n",
        "plt.xlabel(\"Device-Hours per Day\")\n",
        "plt.ylabel(\"Households\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot: peak single-appliance hours (hist; ≤ 24)\n",
        "plt.figure(figsize=(8,4))\n",
        "peak_single_appliance_hours.plot(kind=\"hist\", bins=20)\n",
        "plt.title(\"Peak Single-Appliance Usage per Household (≤ 24)\")\n",
        "plt.xlabel(\"Hours per Day (max per appliance)\")\n",
        "plt.ylabel(\"Households\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OkMIBE7YFA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features Engineering Process\n",
        "\n",
        "# 1) Aggregate appliance data into household-level features\n",
        "apps = apps_rural.copy()\n",
        "\n",
        "# (a) Total usage hours per household (sum of all appliances)\n",
        "hh_usage = apps.groupby(\"hhid\")[\"usage_hours\"].sum().reset_index()\n",
        "hh_usage.rename(columns={\"usage_hours\": \"total_usage_hours\"}, inplace=True)\n",
        "\n",
        "# (b) Number of unique appliance types per household\n",
        "hh_unique_apps_count = apps.groupby(\"hhid\")[\"q403\"].nunique().reset_index()\n",
        "hh_unique_apps_count.rename(columns={\"q403\": \"unique_appliance_count\"}, inplace=True)\n",
        "\n",
        "# (c) Total number of appliance instances per household\n",
        "hh_total_apps_count = apps.groupby(\"hhid\").size().reset_index(name=\"total_appliance_instances\")\n",
        "\n",
        "\n",
        "# (d) Ownership flags for all appliance types\n",
        "# Create dummy variables for all appliance types\n",
        "ownership_flags = pd.get_dummies(apps[['hhid', 'q403']], columns=['q403'], prefix='owns')\n",
        "\n",
        "# Aggregate the ownership flags by household, taking the maximum value (1 if owned, 0 if not)\n",
        "ownership_flags = ownership_flags.groupby('hhid').max().reset_index()\n",
        "\n",
        "\n",
        "# 2) Use HH_rural for household data (includes geo info, hhsize, and income)\n",
        "# Include hhsize_decoded and hhincome_decoded as requested\n",
        "hh_geo = hh_rural[[\"hhid\", \"lga\", \"state\", \"eaid\", \"zone\", \"hhsize_decoded\", \"hhincome_decoded\"]].copy()\n",
        "\n",
        "\n",
        "# 3) Merge all features into one household table\n",
        "household_features = hh_geo.merge(hh_usage, on=\"hhid\", how=\"left\")\n",
        "household_features = household_features.merge(hh_unique_apps_count, on=\"hhid\", how=\"left\")\n",
        "household_features = household_features.merge(hh_total_apps_count, on=\"hhid\", how=\"left\") # Merge the new feature\n",
        "# Merge the corrected ownership flags\n",
        "household_features = household_features.merge(ownership_flags, on=\"hhid\", how=\"left\")\n",
        "\n",
        "# Note: hhsize_decoded and hhincome_decoded are kept in the dataframe\n",
        "\n",
        "# Remove rows with missing values in the features that WILL BE used for clustering\n",
        "# This ensures that X_scaled does not contain NaNs\n",
        "# The clustering features do NOT include hhsize_decoded or hhincome_decoded based on previous decisions\n",
        "clustering_feature_cols = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\"] + [col for col in household_features.columns if col.startswith(\"owns_\")]\n",
        "household_features.dropna(subset=clustering_feature_cols, inplace=True)\n",
        "print(f\"\\nShape of household_features after removing rows with missing values for clustering features: {household_features.shape}\")\n",
        "\n",
        "\n",
        "# 4) Normalize/Standardize features for clustering\n",
        "# Use the defined clustering_feature_cols for scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(household_features[clustering_feature_cols])\n",
        "\n",
        "# Display the final feature table and scaled data\n",
        "display(household_features)"
      ],
      "metadata": {
        "id": "QLk-zhwNCmv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fb38573"
      },
      "source": [
        "# Using Elbow method and Dendrogram for Kmeans (K) and Agglomerative (n)\n",
        "\n",
        "# Based on features from Feature Engineering (excluding hhsize_decoded in clustering_feature_cols)\n",
        "\n",
        "def find_k(X, method=\"kmeans\", k_range=range(2,10), linkage_method=\"ward\"):\n",
        "    if method == \"kmeans\":\n",
        "        inertia_vals = []\n",
        "        for k in k_range:\n",
        "            model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "            model.fit(X)\n",
        "            inertia_vals.append(model.inertia_)\n",
        "\n",
        "        # Plot Elbow Curve For KMeans\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.plot(k_range, inertia_vals, marker='o')\n",
        "        plt.title(\"Elbow\")\n",
        "        plt.xlabel(\"Number of clusters (k)\")\n",
        "        plt.ylabel(\"Inertia\")\n",
        "        plt.show()\n",
        "\n",
        "    elif method == \"agglomerative\":\n",
        "        # Plot Dendrogram for Agglomerative\n",
        "        plt.figure(figsize=(8,4))\n",
        "        Z = linkage(X, method=linkage_method)\n",
        "        dendrogram(Z, truncate_mode=\"lastp\", p=20, show_leaf_counts=True)\n",
        "        plt.title(f\"Dendrogram\")\n",
        "        plt.xlabel(\"Samples\")\n",
        "        plt.ylabel(\"Distance\")\n",
        "        plt.show()\n",
        "\n",
        "# For KMeans (Elbow)\n",
        "find_k(X_scaled, method=\"kmeans\", k_range=range(2,10))\n",
        "\n",
        "# For Agglomerative (Dendrogram)\n",
        "find_k(X_scaled, method=\"agglomerative\", linkage_method=\"ward\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Clustering (KMeans, DBSCAN, and Agglomerative)\n",
        "\n",
        "# Use the clustering_feature_cols list defined in the Feature Engineering cell\n",
        "# This list now includes 'total_usage_hours', 'unique_appliance_count', 'total_appliance_instances', and ownership flags (excluding hhsize_decoded)\n",
        "\n",
        "\n",
        "# Apply KMeans clustering (k=3)\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
        "household_features['kmeans_cluster'] = kmeans.fit_predict(X_scaled) # Fit and predict on scaled data\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "household_features['dbscan_cluster'] = dbscan.fit_predict(X_scaled) # Fit and predict on scaled data\n",
        "\n",
        "# Apply Agglomerative Clustering (n=3)\n",
        "agglo = AgglomerativeClustering(n_clusters=3)\n",
        "household_features['agglo_cluster'] = agglo.fit_predict(X_scaled) # Fit and predict on scaled data\n",
        "\n",
        "# Display final dataframe with clustering results (showing key features and cluster assignments)\n",
        "display(household_features[['hhid'] + clustering_feature_cols + ['kmeans_cluster', 'dbscan_cluster', 'agglo_cluster']])"
      ],
      "metadata": {
        "id": "U5FLQsRqex31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Clusters\n",
        "# Note: Plotting high-dimensional clusters on 2D scatter plots can be difficult\n",
        "# We can attempt to plot using the first two features or the first two PCA components later.\n",
        "# For a basic visualization, let's use total_usage_hours and unique_appliance_count if they are in clustering_feature_cols\n",
        "\n",
        "plot_features = []\n",
        "if 'total_usage_hours' in clustering_feature_cols and 'unique_appliance_count' in clustering_feature_cols:\n",
        "    plot_features = ['total_usage_hours', 'unique_appliance_count']\n",
        "elif 'total_usage_hours' in clustering_feature_cols and 'total_appliance_instances' in clustering_feature_cols:\n",
        "     plot_features = ['total_usage_hours', 'total_appliance_instances']\n",
        "\n",
        "if len(plot_features) == 2:\n",
        "    # Plot KMeans clusters\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    colors = ['red', 'green', 'blue', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan'] # Extended colors\n",
        "    for cluster_id in sorted(household_features['kmeans_cluster'].unique()):\n",
        "        if cluster_id != -1: # Exclude noise for plot legend if present in other methods\n",
        "            color_index = cluster_id % len(colors) # Cycle through colors\n",
        "            color = colors[color_index]\n",
        "            plt.scatter(household_features[household_features['kmeans_cluster'] == cluster_id][plot_features[0]],\n",
        "                        household_features[household_features['kmeans_cluster'] == cluster_id][plot_features[1]],\n",
        "                        c=color,\n",
        "                        label=f'Cluster {cluster_id}',\n",
        "                        alpha=0.6) # Add some transparency\n",
        "    plt.title(f'KMeans Clustering')\n",
        "    plt.xlabel(plot_features[0])\n",
        "    plt.ylabel(plot_features[1])\n",
        "    plt.legend()\n",
        "    plt.grid(False) # Remove grid\n",
        "    plt.show()\n",
        "\n",
        "    # Plot DBSCAN clusters\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for cluster_id in sorted(household_features['dbscan_cluster'].unique()):\n",
        "        if cluster_id != -1:\n",
        "            color_index = cluster_id % len(colors) # Cycle through colors\n",
        "            color = colors[color_index]\n",
        "            label = f'Cluster {cluster_id}'\n",
        "            alpha = 0.6\n",
        "        else:\n",
        "            color = 'gray' # Color for noise points\n",
        "            label = 'Noise'\n",
        "            alpha = 0.4 # More transparency for noise\n",
        "\n",
        "        plt.scatter(household_features[household_features['dbscan_cluster'] == cluster_id][plot_features[0]],\n",
        "                    household_features[household_features['dbscan_cluster'] == cluster_id][plot_features[1]],\n",
        "                    c=color,\n",
        "                    label=label,\n",
        "                    alpha=alpha)\n",
        "    plt.title(f'DBSCAN')\n",
        "    plt.xlabel(plot_features[0])\n",
        "    plt.ylabel(plot_features[1])\n",
        "    # plt.legend() # Removed legend for DBSCAN\n",
        "    plt.grid(False) # Remove grid\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Agglomerative Clustering clusters\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for cluster_id in sorted(household_features['agglo_cluster'].unique()):\n",
        "         if cluster_id != -1: # Exclude noise for plot legend if present in other methods\n",
        "            color_index = cluster_id % len(colors) # Cycle through colors\n",
        "            color = colors[color_index]\n",
        "            plt.scatter(household_features[household_features['agglo_cluster'] == cluster_id][plot_features[0]],\n",
        "                        household_features[household_features['agglo_cluster'] == cluster_id][plot_features[1]],\n",
        "                        c=color,\n",
        "                        label=f'Cluster {cluster_id}',\n",
        "                        alpha=0.6) # Add some transparency\n",
        "    plt.title(f'Agglomerative Clustering')\n",
        "    plt.xlabel(plot_features[0])\n",
        "    plt.ylabel(plot_features[1])\n",
        "    plt.legend()\n",
        "    plt.grid(False) # Remove grid\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nCannot plot clusters on a 2D scatter plot with the selected features.\")\n",
        "    print(\"Please ensure clustering_feature_cols contains at least two features suitable for plotting, or use PCA results for visualization.\")"
      ],
      "metadata": {
        "id": "qy7f2ztnnttJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate KMeans clustering using Silhouette Score and Davies-Bouldin Index\n",
        "kmeans_silhouette = silhouette_score(X_scaled, household_features['kmeans_cluster'])\n",
        "kmeans_davies_bouldin = davies_bouldin_score(X_scaled, household_features['kmeans_cluster'])\n",
        "\n",
        "# Output KMeans evaluation results\n",
        "print(f\"KMeans\")\n",
        "print(f\"  Silhouette Score: {kmeans_silhouette:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {kmeans_davies_bouldin:.4f}\")\n",
        "\n",
        "# Evaluate Agglomerative Clustering using Silhouette Score and Davies-Bouldin Index\n",
        "agglo_silhouette = silhouette_score(X_scaled, household_features['agglo_cluster'])\n",
        "agglo_davies_bouldin = davies_bouldin_score(X_scaled, household_features['agglo_cluster'])\n",
        "\n",
        "# Output Agglomerative Clustering evaluation results\n",
        "print(f\"\\nAgglomerative\")\n",
        "print(f\"  Silhouette Score: {agglo_silhouette:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {agglo_davies_bouldin:.4f}\")\n",
        "\n",
        "# Note: Evaluating DBSCAN requires different approaches due to the presence of noise.\n",
        "# Metrics like Silhouette Score can be calculated on the non-noise points,\n",
        "# but interpreting them requires careful consideration of how DBSCAN handles outliers."
      ],
      "metadata": {
        "id": "3cb110l8mVJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA\n",
        "\n",
        "# Use the clustering_feature_cols list defined in the Feature Engineering cell\n",
        "\n",
        "# Apply PCA to reduce dimensions (e.g., to 2 components)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(household_features[clustering_feature_cols])  # Apply PCA on the correct feature columns\n",
        "\n",
        "# Clustering with PCA\n",
        "# Apply KMeans clustering (k=3) on the PCA-reduced data\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
        "kmeans_labels = kmeans.fit_predict(X_pca)\n",
        "\n",
        "# Apply DBSCAN clustering on the PCA-reduced data\n",
        "# You may need to tune eps and min_samples based on your data\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(X_pca)\n",
        "\n",
        "# Apply Agglomerative Clustering (n=3) on the PCA-reduced data\n",
        "agglo = AgglomerativeClustering(n_clusters=3)\n",
        "agglo_labels = agglo.fit_predict(X_pca)\n",
        "\n",
        "# Assign clustering results to the household_features dataframe\n",
        "# Ensure that household_features still has the correct index for merging\n",
        "household_features['kmeans_pca_cluster'] = kmeans_labels\n",
        "household_features['dbscan_pca_cluster'] = dbscan_labels # Add DBSCAN cluster labels\n",
        "household_features['agglo_pca_cluster'] = agglo_labels\n",
        "\n",
        "# Display Clustering with PCA\n",
        "print(\"\\nHousehold Features with PCA Cluster\")\n",
        "display(household_features[['hhid'] + clustering_feature_cols + ['kmeans_pca_cluster', 'dbscan_pca_cluster', 'agglo_pca_cluster']])"
      ],
      "metadata": {
        "id": "_pvkWguarlUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Clusters with PCA\n",
        "\n",
        "# Plot the clusters for KMeans\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Use the cluster labels for coloring\n",
        "scatter_kmeans = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
        "plt.title('KMeans')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(*scatter_kmeans.legend_elements(), title=\"Clusters\")\n",
        "plt.grid(False) # Remove grid\n",
        "plt.show()\n",
        "\n",
        "# Plot the clusters for DBSCAN\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Use the cluster labels for coloring\n",
        "scatter_dbscan = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.6)\n",
        "plt.title('DBSCAN')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "#plt.legend(*scatter_dbscan.legend_elements(), title=\"Clusters\") # Removed legend\n",
        "plt.grid(False) # Remove grid\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot the clusters for Agglomerative\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Use the cluster labels for coloring\n",
        "scatter_agglo = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=agglo_labels, cmap='viridis', alpha=0.6)\n",
        "plt.title('Agglomerative Clustering')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(*scatter_agglo.legend_elements(), title=\"Clusters\")\n",
        "plt.grid(False) # Remove grid\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hYVGm4zTlbQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "# Evaluate KMeans clustering using Silhouette Score and Davies-Bouldin Index\n",
        "silhouette_kmeans = silhouette_score(X_pca, kmeans_labels)\n",
        "dbi_kmeans = davies_bouldin_score(X_pca, kmeans_labels)\n",
        "\n",
        "# Evaluate DBSCAN clustering using Silhouette Score and Davies-Bouldin Index\n",
        "# Note: Silhouette Score for DBSCAN is typically calculated on non-noise points\n",
        "# and interpretation needs care. Davies-Bouldin can be calculated on all points.\n",
        "# We'll calculate on all points for simplicity here, but be mindful of interpretation.\n",
        "if len(set(dbscan_labels)) > 1: # Need more than 1 cluster to calculate silhouette\n",
        "    silhouette_dbscan = silhouette_score(X_pca, dbscan_labels)\n",
        "    dbi_dbscan = davies_bouldin_score(X_pca, dbscan_labels)\n",
        "else:\n",
        "    silhouette_dbscan = None # Cannot calculate silhouette with only one cluster or all noise\n",
        "    dbi_dbscan = None\n",
        "\n",
        "\n",
        "# Evaluate Agglomerative Clustering using Silhouette Score and Davies-Bouldin Index\n",
        "silhouette_agglo = silhouette_score(X_pca, agglo_labels)\n",
        "dbi_agglo = davies_bouldin_score(X_pca, agglo_labels)\n",
        "\n",
        "# Print evaluation results for clustering with PCA\n",
        "print(\"Clustering with PCA\")\n",
        "\n",
        "print(f\"\\nKMeans\")\n",
        "print(f\"  Silhouette Score: {silhouette_kmeans:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {dbi_kmeans:.4f}\")\n",
        "\n",
        "print(f\"\\nDBSCAN\")\n",
        "if silhouette_dbscan is not None:\n",
        "    print(f\"  Silhouette Score: {silhouette_dbscan:.4f}\")\n",
        "else:\n",
        "    print(\"  Silhouette Score: Cannot be calculated (only one cluster or all noise)\")\n",
        "\n",
        "if dbi_dbscan is not None:\n",
        "    print(f\"  Davies-Bouldin Index: {dbi_dbscan:.4f}\")\n",
        "else:\n",
        "     print(\"  Davies-Bouldin Index: Cannot be calculated (only one cluster or all noise)\")\n",
        "\n",
        "print(f\"\\nAgglomerative\")\n",
        "print(f\"  Silhouette Score: {silhouette_agglo:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {dbi_agglo:.4f}\")"
      ],
      "metadata": {
        "id": "jltClMazkoTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4c3a34f"
      },
      "source": [
        "# Analyze the characteristics of KMeans PCA clusters\n",
        "\n",
        "# Define the features to include in the cluster analysis\n",
        "analysis_features = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\"] + [col for col in household_features.columns if col.startswith(\"owns_\")]\n",
        "\n",
        "# Group by KMeans PCA cluster and calculate the mean of the analysis features\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[analysis_features].mean()\n",
        "\n",
        "print(\"KMeans PCA Cluster Analysis\")\n",
        "display(kmeans_pca_cluster_analysis)\n",
        "\n",
        "# For binary ownership flags (owns_*), the mean represents the proportion of households in the cluster that own the appliance."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title unique_appliance_count vs total_appliance_instances\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "kmeans_pca_cluster_analysis.plot(kind='scatter', x='unique_appliance_count', y='total_appliance_instances', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "X4BwT6T7p_VX"
      }
    },
    {
      "source": [
        "# @title total_usage_hours vs unique_appliance_count\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "kmeans_pca_cluster_analysis.plot(kind='scatter', x='total_usage_hours', y='unique_appliance_count', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "keGnNDZ6p2fp"
      }
    },
    {
      "source": [
        "# @title total_usage_hours\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "kmeans_pca_cluster_analysis['total_usage_hours'].plot(kind='hist', bins=20, title='total_usage_hours')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "Hs7vn6adpuqp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4f1700"
      },
      "source": [
        "# Visualize KMeans PCA Cluster Characteristics\n",
        "\n",
        "# Plotting selected features for comparison\n",
        "features_to_plot = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\", \"owns_Fan\", \"owns_Television\", \"owns_Laptop / Computer\", \"owns_Light bulb\"]\n",
        "\n",
        "kmeans_pca_cluster_analysis[features_to_plot].T.plot(kind='bar', figsize=(6, 6))\n",
        "plt.title('Mean Feature Values per KMeans PCA Cluster')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Mean Value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Cluster')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can create individual plots for more detailed comparison if needed\n",
        "\n",
        "# For example, plotting total_usage_hours per cluster:\n",
        "kmeans_pca_cluster_analysis['total_usage_hours'].plot(kind='bar', figsize=(6,4))\n",
        "plt.title('Average Total Usage Hours per KMeans PCA Cluster')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Average Total Usage Hours')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4qWqyjJTDVwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geographic Analysis of KMeans PCA Clusters\n",
        "\n",
        "print(\"Geographic Distribution of KMeans PCA Clusters\")\n",
        "\n",
        "# Cross-tabulation of Cluster vs. Zone\n",
        "print(\"\\nCluster distribution across Zones:\")\n",
        "cluster_zone_A = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'])\n",
        "display(cluster_zone_A)\n",
        "\n",
        "print(\"\\nCluster proportion across Zones:\")\n",
        "cluster_zone_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_prop)\n",
        "\n",
        "# Cross-tabulation of Cluster vs. State\n",
        "print(\"\\nCluster distribution across States:\")\n",
        "cluster_state_A = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'])\n",
        "display(cluster_state_A)\n",
        "\n",
        "print(\"\\nCluster proportion across States:\")\n",
        "cluster_state_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'], normalize='index') # Proportions within each cluster summing to 1\n",
        "display(cluster_state_prop)\n",
        "\n",
        "# Analyze distribution by LGA for a deeper look\n",
        "print(\"\\nCluster distribution across LGAs:\")\n",
        "cluster_lga = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['lga'])\n",
        "display(cluster_lga)\n",
        "\n",
        "# Analyzing by EAID is also possible but will result in a very large table\n",
        "# For EAID:\n",
        "# cluster_eaid = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['eaid'])\n",
        "# display(cluster_eaid)"
      ],
      "metadata": {
        "id": "jR7seXqx-Zff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Dive: Analyze hhsize_decoded distribution per KMeans PCA Cluster\n",
        "\n",
        "print(\"Household Size (hhsize_decoded) Analysis per KMeans PCA Cluster\")\n",
        "\n",
        "# Group by cluster and describe the hhsize_decoded distribution\n",
        "hhsize_analysis = household_features.groupby('kmeans_pca_cluster')['hhsize_decoded'].describe()\n",
        "\n",
        "print(\"\\nHousehold Size Distribution Summary per Cluster:\")\n",
        "display(hhsize_analysis)\n",
        "\n",
        "# Optional: Plotting the distribution (e.g., box plots) for better visualization\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='kmeans_pca_cluster', y='hhsize_decoded', data=household_features)\n",
        "plt.title('Household Size Distribution per KMeans PCA Cluster')\n",
        "plt.xlabel('KMeans PCA Cluster')\n",
        "plt.ylabel('Household Size (hhsize_decoded)')\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "13FefYGJ-40r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c143b78f"
      },
      "source": [
        "# Deep Dive: Analyze hhincome_decoded distribution per KMeans PCA Cluster\n",
        "\n",
        "print(\"Household Income (hhincome_decoded) Analysis per KMeans PCA Cluster\")\n",
        "\n",
        "# Diagnosis: Print columns before crosstab\n",
        "print(\"\\nColumns in household_features before crosstab:\")\n",
        "print(household_features.columns)\n",
        "# End Diagnosis\n",
        "\n",
        "\n",
        "# Cross-tabulation of Cluster vs. Household Income (counts)\n",
        "print(\"\\nCluster distribution across Household Income Categories (Counts):\")\n",
        "cluster_income_counts = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'])\n",
        "display(cluster_income_counts)\n",
        "\n",
        "# Cross-tabulation of Cluster vs. Household Income (proportions within each cluster)\n",
        "print(\"\\nCluster proportion across Household Income Categories (Proportions within each cluster):\")\n",
        "cluster_income_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='index') # Proportions within each cluster summing to 1\n",
        "display(cluster_income_prop)\n",
        "\n",
        "# Optional: You could also normalize='columns' to see the proportion of each income category within each cluster.\n",
        "# print(\"\\nProportion of each Income Category within each Cluster:\")\n",
        "# cluster_income_prop_cols = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='columns')\n",
        "# display(cluster_income_prop_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26bcabc4"
      },
      "source": [
        "# Synthesize information and describe each KMeans PCA cluster\n",
        "\n",
        "print(\"Detailed Profile of KMeans PCA Clusters:\\n\")\n",
        "\n",
        "# Recreate analysis variables\n",
        "# Define the features to include in the cluster analysis\n",
        "analysis_features = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\"] + [col for col in household_features.columns if col.startswith(\"owns_\")]\n",
        "\n",
        "# Group by KMeans PCA cluster and calculate the mean of the analysis features\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[analysis_features].mean()\n",
        "\n",
        "# Geographic Analysis variables\n",
        "cluster_zone_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'], normalize='index')\n",
        "cluster_state_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'], normalize='index')\n",
        "cluster_lga = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['lga'])\n",
        "\n",
        "# Household Size Analysis variable\n",
        "hhsize_analysis = household_features.groupby('kmeans_pca_cluster')['hhsize_decoded'].describe()\n",
        "\n",
        "# Household Income Analysis variables\n",
        "cluster_income_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "\n",
        "\n",
        "# Get the unique cluster IDs\n",
        "cluster_ids = sorted(household_features['kmeans_pca_cluster'].unique())\n",
        "\n",
        "# Loop through each cluster to generate the profile\n",
        "for cluster_id in cluster_ids:\n",
        "    print(f\"--- Cluster {cluster_id} Profile ---\")\n",
        "\n",
        "    # 1. Appliance Ownership and Usage\n",
        "    print(\"\\nAppliance Ownership and Usage:\")\n",
        "    cluster_features = kmeans_pca_cluster_analysis.loc[cluster_id]\n",
        "\n",
        "    print(f\"  - Average Total Usage Hours: {cluster_features['total_usage_hours']:.2f}\")\n",
        "    print(f\"  - Average Unique Appliance Count: {cluster_features['unique_appliance_count']:.2f}\")\n",
        "    print(f\"  - Average Total Appliance Instances: {cluster_features['total_appliance_instances']:.2f}\")\n",
        "\n",
        "    print(\"  - Appliance Ownership Proportions:\")\n",
        "    ownership_cols = [col for col in kmeans_pca_cluster_analysis.columns if col.startswith(\"owns_\")]\n",
        "    for col in ownership_cols:\n",
        "        appliance_name = col.replace(\"owns_\", \"\")\n",
        "        print(f\"    - {appliance_name}: {cluster_features[col]:.2f}\")\n",
        "\n",
        "    # 2. Geographic Location\n",
        "    print(\"\\nGeographic Location:\")\n",
        "    cluster_zone_dist = cluster_zone_prop.loc[cluster_id].sort_values(ascending=False)\n",
        "    cluster_state_dist = cluster_state_prop.loc[cluster_id].sort_values(ascending=False).head() # Show top 5 states\n",
        "    cluster_lga_dist = cluster_lga.loc[cluster_id].sort_values(ascending=False).head() # Show top 5 LGAs by count\n",
        "\n",
        "\n",
        "    print(\"  - Distribution by Zone (Proportion):\")\n",
        "    display(cluster_zone_dist.to_frame().T)\n",
        "\n",
        "    print(\"  - Top 5 States (Proportion within cluster):\")\n",
        "    display(cluster_state_dist.to_frame().T)\n",
        "\n",
        "    print(\"  - Top 5 LGAs (Count):\")\n",
        "    display(cluster_lga_dist.to_frame().T)\n",
        "\n",
        "\n",
        "    # 3. Household Size\n",
        "    print(\"\\nHousehold Size (hhsize_decoded):\")\n",
        "    hhsize_desc = hhsize_analysis.loc[cluster_id]\n",
        "    print(f\"  - Mean: {hhsize_desc['mean']:.2f}\")\n",
        "    print(f\"  - Median: {hhsize_desc['50%']:.2f}\")\n",
        "    print(f\"  - Std Dev: {hhsize_desc['std']:.2f}\")\n",
        "    print(f\"  - Min: {hhsize_desc['min']:.2f}\")\n",
        "    print(f\"  - Max: {hhsize_desc['max']:.2f}\")\n",
        "\n",
        "\n",
        "    # 4. Household Income\n",
        "    print(\"\\nHousehold Income (hhincome_decoded):\")\n",
        "    income_dist = cluster_income_prop.loc[cluster_id].sort_values(ascending=False)\n",
        "    print(\"  - Distribution by Income Source (Proportion within cluster):\")\n",
        "    display(income_dist.to_frame().T)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\") # Separator for clarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7dbde2e"
      },
      "source": [
        "# Geographic Analysis for KMeans (with PCA)\n",
        "print(\"\\nGeographic Distribution of KMeans PCA Clusters\")\n",
        "print(\"\\nCluster proportion across Zones (KMeans PCA):\")\n",
        "cluster_zone_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_kmeans_pca)\n",
        "\n",
        "print(\"\\nCluster proportion across States (KMeans PCA):\")\n",
        "cluster_state_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_kmeans_pca)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (KMeans PCA - Counts):\")\n",
        "cluster_lga_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['lga'])\n",
        "display(cluster_lga_kmeans_pca)\n",
        "\n",
        "\n",
        "# Geographic Analysis for Agglomerative (with PCA)\n",
        "print(\"\\nGeographic Distribution of Agglomerative PCA Clusters\")\n",
        "print(\"\\nCluster proportion across Zones (Agglomerative PCA):\")\n",
        "cluster_zone_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_agglo_pca)\n",
        "\n",
        "print(\"\\nCluster proportion across States (Agglomerative PCA):\")\n",
        "cluster_state_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_agglo_pca)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (Agglomerative PCA - Counts):\")\n",
        "cluster_lga_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['lga'])\n",
        "display(cluster_lga_agglo_pca)\n",
        "\n",
        "\n",
        "# Geographic Analysis for DBSCAN (with PCA)\n",
        "print(\"\\nGeographic Distribution of DBSCAN PCA Clusters\")\n",
        "# Exclude noise points (-1) for meaningful geographic analysis of core clusters\n",
        "dbscan_pca_core_clusters_geo = household_features[household_features['dbscan_pca_cluster'] != -1]\n",
        "\n",
        "if not dbscan_pca_core_clusters_geo.empty:\n",
        "    print(\"\\nCluster proportion across Zones (DBSCAN PCA - Core Clusters):\")\n",
        "    cluster_zone_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['zone'], normalize='index')\n",
        "    display(cluster_zone_dbscan_pca)\n",
        "\n",
        "    print(\"\\nCluster proportion across States (DBSCAN PCA - Core Clusters):\")\n",
        "    cluster_state_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['state'], normalize='index')\n",
        "    display(cluster_state_dbscan_pca)\n",
        "\n",
        "    print(\"\\nCluster distribution across LGAs (DBSCAN PCA - Core Clusters - Counts):\")\n",
        "    cluster_lga_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['lga'])\n",
        "    display(cluster_lga_dbscan_pca)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results for geographic analysis.\")\n",
        "\n",
        "\n",
        "# Household Size Analysis\n",
        "print(\"\\nHousehold Size (hhsize_decoded) Analysis per Cluster\")\n",
        "\n",
        "# KMeans\n",
        "print(\"\\nHousehold Size Distribution Summary per KMeans Cluster:\")\n",
        "hhsize_kmeans = household_features.groupby('kmeans_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_kmeans)\n",
        "\n",
        "# Agglomerative\n",
        "print(\"\\nHousehold Size Distribution Summary per Agglomerative Cluster:\")\n",
        "hhsize_agglo = household_features.groupby('agglo_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_agglo)\n",
        "\n",
        "# DBSCAN (Excluding noise)\n",
        "print(\"\\nHousehold Size Distribution Summary per DBSCAN Cluster (Excluding Noise):\")\n",
        "if not dbscan_core_clusters.empty:\n",
        "    hhsize_dbscan = dbscan_core_clusters.groupby('dbscan_cluster')['hhsize_decoded'].describe()\n",
        "    display(hhsize_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for household size analysis.\")\n",
        "\n",
        "# KMeans PCA\n",
        "print(\"\\nHousehold Size Distribution Summary per KMeans PCA Cluster:\")\n",
        "hhsize_kmeans_pca = household_features.groupby('kmeans_pca_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_kmeans_pca)\n",
        "\n",
        "# Agglomerative PCA\n",
        "print(\"\\nHousehold Size Distribution Summary per Agglomerative PCA Cluster:\")\n",
        "hhsize_agglo_pca = household_features.groupby('agglo_pca_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_agglo_pca)\n",
        "\n",
        "# DBSCAN PCA (Excluding noise)\n",
        "print(\"\\nHousehold Size Distribution Summary per DBSCAN PCA Cluster (Excluding Noise):\")\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    hhsize_dbscan_pca = dbscan_pca_core_clusters.groupby('dbscan_pca_cluster')['hhsize_decoded'].describe()\n",
        "    display(hhsize_dbscan_pca)\n",
        "else:\n",
        "     print(\"No core clusters found in DBSCAN (with PCA) results for household size analysis.\")\n",
        "\n",
        "\n",
        "# Household Income Analysis\n",
        "print(\"\\nHousehold Income (hhincome_decoded) Analysis per Cluster\")\n",
        "\n",
        "# KMeans\n",
        "print(\"\\nCluster proportion across Household Income Categories (KMeans):\")\n",
        "income_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_kmeans)\n",
        "\n",
        "# Agglomerative\n",
        "print(\"\\nCluster proportion across Household Income Categories (Agglomerative):\")\n",
        "income_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_agglo)\n",
        "\n",
        "# DBSCAN (Excluding noise)\n",
        "print(\"\\nCluster proportion across Household Income Categories (DBSCAN - Core Clusters):\")\n",
        "if not dbscan_core_clusters.empty:\n",
        "    income_dbscan = pd.crosstab(dbscan_core_clusters['dbscan_cluster'], dbscan_core_clusters['hhincome_decoded'], normalize='index')\n",
        "    display(income_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for income analysis.\")\n",
        "\n",
        "\n",
        "# KMeans PCA\n",
        "print(\"\\nCluster proportion across Household Income Categories (KMeans PCA):\")\n",
        "income_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_kmeans_pca)\n",
        "\n",
        "# Agglomerative PCA\n",
        "print(\"\\nCluster proportion across Household Income Categories (Agglomerative PCA):\")\n",
        "income_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_agglo_pca)\n",
        "\n",
        "# DBSCAN PCA (Excluding noise)\n",
        "print(\"\\nCluster proportion across Household Income Categories (DBSCAN PCA - Core Clusters):\")\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    income_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters['dbscan_pca_cluster'], dbscan_pca_core_clusters['hhincome_decoded'], normalize='index')\n",
        "    display(income_dbscan_pca)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results for income analysis.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fe47a28"
      },
      "source": [
        "# Geographic Analysis for KMeans (without PCA)\n",
        "print(\"\\nGeographic Distribution of KMeans Clusters (without PCA)\")\n",
        "print(\"\\nCluster proportion across Zones (KMeans):\")\n",
        "cluster_zone_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_kmeans)\n",
        "\n",
        "print(\"\\nCluster proportion across States (KMeans):\")\n",
        "cluster_state_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_kmeans)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (KMeans - Counts):\")\n",
        "# Displaying counts for LGA as proportions can be too granular\n",
        "cluster_lga_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['lga'])\n",
        "display(cluster_lga_kmeans)\n",
        "\n",
        "\n",
        "# Geographic Analysis for Agglomerative (without PCA)\n",
        "print(\"\\nGeographic Distribution of Agglomerative Clusters (without PCA)\")\n",
        "print(\"\\nCluster proportion across Zones (Agglomerative):\")\n",
        "cluster_zone_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_agglo)\n",
        "\n",
        "print(\"\\nCluster proportion across States (Agglomerative):\")\n",
        "cluster_state_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_agglo)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (Agglomerative - Counts):\")\n",
        "cluster_lga_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['lga'])\n",
        "display(cluster_lga_agglo)\n",
        "\n",
        "\n",
        "# Geographic Analysis for DBSCAN (without PCA)\n",
        "print(\"\\nGeographic Distribution of DBSCAN Clusters (without PCA)\")\n",
        "# Exclude noise points (-1) for meaningful geographic analysis of core clusters\n",
        "dbscan_core_clusters_geo = household_features[household_features['dbscan_cluster'] != -1]\n",
        "\n",
        "if not dbscan_core_clusters_geo.empty:\n",
        "    print(\"\\nCluster proportion across Zones (DBSCAN - Core Clusters):\")\n",
        "    cluster_zone_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['zone'], normalize='index')\n",
        "    display(cluster_zone_dbscan)\n",
        "\n",
        "    print(\"\\nCluster proportion across States (DBSCAN - Core Clusters):\")\n",
        "    cluster_state_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['state'], normalize='index')\n",
        "    display(cluster_state_dbscan)\n",
        "\n",
        "    print(\"\\nCluster distribution across LGAs (DBSCAN - Core Clusters - Counts):\")\n",
        "    cluster_lga_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['lga'])\n",
        "    display(cluster_lga_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for geographic analysis.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3097039d"
      },
      "source": [
        "# 8) Calculate mean feature values for KMeans clusters (with PCA)\n",
        "print(\"\\nMean Feature Values per KMeans Cluster (with PCA)\")\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[clustering_feature_cols].mean()\n",
        "display(kmeans_pca_cluster_analysis)\n",
        "\n",
        "# 9) Calculate mean feature values for Agglomerative clusters (with PCA)\n",
        "print(\"\\nMean Feature Values per Agglomerative Cluster (with PCA)\")\n",
        "agglo_pca_cluster_analysis = household_features.groupby('agglo_pca_cluster')[clustering_feature_cols].mean()\n",
        "display(agglo_pca_cluster_analysis)\n",
        "\n",
        "# 10) Calculate mean feature values for DBSCAN clusters (with PCA)\n",
        "# Exclude noise points (-1) for mean calculation\n",
        "print(\"\\nMean Feature Values per DBSCAN Cluster (with PCA, excluding noise)\")\n",
        "dbscan_pca_core_clusters = household_features[household_features['dbscan_pca_cluster'] != -1]\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    dbscan_pca_cluster_analysis = dbscan_pca_core_clusters.groupby('dbscan_pca_cluster')[clustering_feature_cols].mean()\n",
        "    display(dbscan_pca_cluster_analysis)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results to calculate mean features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1974d459"
      },
      "source": [
        "# 5) Calculate mean feature values for KMeans clusters (without PCA)\n",
        "print(\"\\nMean Feature Values per KMeans Cluster (without PCA)\")\n",
        "kmeans_cluster_analysis = household_features.groupby('kmeans_cluster')[clustering_feature_cols].mean()\n",
        "display(kmeans_cluster_analysis)\n",
        "\n",
        "# 6) Calculate mean feature values for Agglomerative clusters (without PCA)\n",
        "print(\"\\nMean Feature Values per Agglomerative Cluster (without PCA)\")\n",
        "agglo_cluster_analysis = household_features.groupby('agglo_cluster')[clustering_feature_cols].mean()\n",
        "display(agglo_cluster_analysis)\n",
        "\n",
        "# 7) Calculate mean feature values for DBSCAN clusters (without PCA)\n",
        "# Exclude noise points (-1) for mean calculation\n",
        "print(\"\\nMean Feature Values per DBSCAN Cluster (without PCA, excluding noise)\")\n",
        "dbscan_core_clusters = household_features[household_features['dbscan_cluster'] != -1]\n",
        "if not dbscan_core_clusters.empty:\n",
        "    dbscan_cluster_analysis = dbscan_core_clusters.groupby('dbscan_cluster')[clustering_feature_cols].mean()\n",
        "    display(dbscan_cluster_analysis)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) to calculate mean features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "531f2dda"
      },
      "source": [
        "# 1) Cross-tabulation of KMeans vs. Agglomerative Clustering (without PCA)\n",
        "print(\"Cross-tabulation: KMeans Clusters vs. Agglomerative Clusters (without PCA)\")\n",
        "crosstab_kmeans_agglo = pd.crosstab(household_features['kmeans_cluster'], household_features['agglo_cluster'])\n",
        "display(crosstab_kmeans_agglo)\n",
        "\n",
        "# 2) Cross-tabulation of KMeans vs. DBSCAN (without PCA)\n",
        "print(\"\\nCross-tabulation: KMeans Clusters vs. DBSCAN Clusters (without PCA)\")\n",
        "crosstab_kmeans_dbscan = pd.crosstab(household_features['kmeans_cluster'], household_features['dbscan_cluster'])\n",
        "display(crosstab_kmeans_dbscan)\n",
        "\n",
        "# 3) Cross-tabulation of Agglomerative Clustering vs. DBSCAN (without PCA)\n",
        "print(\"\\nCross-tabulation: Agglomerative Clusters vs. DBSCAN Clusters (without PCA)\")\n",
        "crosstab_agglo_dbscan = pd.crosstab(household_features['agglo_cluster'], household_features['dbscan_cluster'])\n",
        "display(crosstab_agglo_dbscan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3539ab86"
      },
      "source": [
        "# 5) Calculate mean feature values for KMeans clusters (without PCA)\n",
        "print(\"\\nMean Feature Values per KMeans Cluster (without PCA)\")\n",
        "kmeans_cluster_analysis = household_features.groupby('kmeans_cluster')[clustering_feature_cols].mean()\n",
        "display(kmeans_cluster_analysis)\n",
        "\n",
        "# 6) Calculate mean feature values for Agglomerative clusters (without PCA)\n",
        "print(\"\\nMean Feature Values per Agglomerative Cluster (without PCA)\")\n",
        "agglo_cluster_analysis = household_features.groupby('agglo_cluster')[clustering_feature_cols].mean()\n",
        "display(agglo_cluster_analysis)\n",
        "\n",
        "# 7) Calculate mean feature values for DBSCAN clusters (without PCA)\n",
        "# Exclude noise points (-1) for mean calculation\n",
        "print(\"\\nMean Feature Values per DBSCAN Cluster (without PCA, excluding noise)\")\n",
        "dbscan_core_clusters = household_features[household_features['dbscan_cluster'] != -1]\n",
        "if not dbscan_core_clusters.empty:\n",
        "    dbscan_cluster_analysis = dbscan_core_clusters.groupby('dbscan_cluster')[clustering_feature_cols].mean()\n",
        "    display(dbscan_cluster_analysis)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) to calculate mean features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9b6d4cf"
      },
      "source": [
        "# 8) Calculate mean feature values for KMeans clusters (with PCA)\n",
        "print(\"\\nMean Feature Values per KMeans Cluster (with PCA)\")\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[clustering_feature_cols].mean()\n",
        "display(kmeans_pca_cluster_analysis)\n",
        "\n",
        "# 9) Calculate mean feature values for Agglomerative clusters (with PCA)\n",
        "print(\"\\nMean Feature Values per Agglomerative Cluster (with PCA)\")\n",
        "agglo_pca_cluster_analysis = household_features.groupby('agglo_pca_cluster')[clustering_feature_cols].mean()\n",
        "display(agglo_pca_cluster_analysis)\n",
        "\n",
        "# 10) Calculate mean feature values for DBSCAN clusters (with PCA)\n",
        "# Exclude noise points (-1) for mean calculation\n",
        "print(\"\\nMean Feature Values per DBSCAN Cluster (with PCA, excluding noise)\")\n",
        "dbscan_pca_core_clusters = household_features[household_features['dbscan_pca_cluster'] != -1]\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    dbscan_pca_cluster_analysis = dbscan_pca_core_clusters.groupby('dbscan_pca_cluster')[clustering_feature_cols].mean()\n",
        "    display(dbscan_pca_cluster_analysis)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results to calculate mean features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17f50803"
      },
      "source": [
        "# Geographic Analysis for KMeans (without PCA)\n",
        "print(\"\\nGeographic Distribution of KMeans Clusters (without PCA)\")\n",
        "print(\"\\nCluster proportion across Zones (KMeans):\")\n",
        "cluster_zone_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_kmeans)\n",
        "\n",
        "print(\"\\nCluster proportion across States (KMeans):\")\n",
        "cluster_state_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_kmeans)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (KMeans - Counts):\")\n",
        "# Displaying counts for LGA as proportions can be too granular\n",
        "cluster_lga_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['lga'])\n",
        "display(cluster_lga_kmeans)\n",
        "\n",
        "\n",
        "# Geographic Analysis for Agglomerative (without PCA)\n",
        "print(\"\\nGeographic Distribution of Agglomerative Clusters (without PCA)\")\n",
        "print(\"\\nCluster proportion across Zones (Agglomerative):\")\n",
        "cluster_zone_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_agglo)\n",
        "\n",
        "print(\"\\nCluster proportion across States (Agglomerative):\")\n",
        "cluster_state_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_agglo)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (Agglomerative - Counts):\")\n",
        "cluster_lga_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['lga'])\n",
        "display(cluster_lga_agglo)\n",
        "\n",
        "\n",
        "# Geographic Analysis for DBSCAN (without PCA)\n",
        "print(\"\\nGeographic Distribution of DBSCAN Clusters (without PCA)\")\n",
        "# Exclude noise points (-1) for meaningful geographic analysis of core clusters\n",
        "dbscan_core_clusters_geo = household_features[household_features['dbscan_cluster'] != -1]\n",
        "\n",
        "if not dbscan_core_clusters_geo.empty:\n",
        "    print(\"\\nCluster proportion across Zones (DBSCAN - Core Clusters):\")\n",
        "    cluster_zone_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['zone'], normalize='index')\n",
        "    display(cluster_zone_dbscan)\n",
        "\n",
        "    print(\"\\nCluster proportion across States (DBSCAN - Core Clusters):\")\n",
        "    cluster_state_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['state'], normalize='index')\n",
        "    display(cluster_state_dbscan)\n",
        "\n",
        "    print(\"\\nCluster distribution across LGAs (DBSCAN - Core Clusters - Counts):\")\n",
        "    cluster_lga_dbscan = pd.crosstab(dbscan_core_clusters_geo['dbscan_cluster'], dbscan_core_clusters_geo['lga'])\n",
        "    display(cluster_lga_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for geographic analysis.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abcb5292"
      },
      "source": [
        "# Geographic Analysis for KMeans (with PCA)\n",
        "print(\"\\nGeographic Distribution of KMeans PCA Clusters\")\n",
        "print(\"\\nCluster proportion across Zones (KMeans PCA):\")\n",
        "cluster_zone_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_kmeans_pca)\n",
        "\n",
        "print(\"\\nCluster proportion across States (KMeans PCA):\")\n",
        "cluster_state_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_kmeans_pca)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (KMeans PCA - Counts):\")\n",
        "cluster_lga_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['lga'])\n",
        "display(cluster_lga_kmeans_pca)\n",
        "\n",
        "\n",
        "# Geographic Analysis for Agglomerative (with PCA)\n",
        "print(\"\\nGeographic Distribution of Agglomerative PCA Clusters\")\n",
        "print(\"\\nCluster proportion across Zones (Agglomerative PCA):\")\n",
        "cluster_zone_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['zone'], normalize='index')\n",
        "display(cluster_zone_agglo_pca)\n",
        "\n",
        "print(\"\\nCluster proportion across States (Agglomerative PCA):\")\n",
        "cluster_state_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['state'], normalize='index')\n",
        "display(cluster_state_agglo_pca)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (Agglomerative PCA - Counts):\")\n",
        "cluster_lga_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['lga'])\n",
        "display(cluster_lga_agglo_pca)\n",
        "\n",
        "\n",
        "# Geographic Analysis for DBSCAN (with PCA)\n",
        "print(\"\\nGeographic Distribution of DBSCAN PCA Clusters\")\n",
        "# Exclude noise points (-1) for meaningful geographic analysis of core clusters\n",
        "dbscan_pca_core_clusters_geo = household_features[household_features['dbscan_pca_cluster'] != -1]\n",
        "\n",
        "if not dbscan_pca_core_clusters_geo.empty:\n",
        "    print(\"\\nCluster proportion across Zones (DBSCAN PCA - Core Clusters):\")\n",
        "    cluster_zone_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['zone'], normalize='index')\n",
        "    display(cluster_zone_dbscan_pca)\n",
        "\n",
        "    print(\"\\nCluster proportion across States (DBSCAN PCA - Core Clusters):\")\n",
        "    cluster_state_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['state'], normalize='index')\n",
        "    display(cluster_state_dbscan_pca)\n",
        "\n",
        "    print(\"\\nCluster distribution across LGAs (DBSCAN PCA - Core Clusters - Counts):\")\n",
        "    cluster_lga_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters_geo['dbscan_pca_cluster'], dbscan_pca_core_clusters_geo['lga'])\n",
        "    display(cluster_lga_dbscan_pca)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results for geographic analysis.\")\n",
        "\n",
        "\n",
        "# Household Size Analysis\n",
        "print(\"\\nHousehold Size (hhsize_decoded) Analysis per Cluster\")\n",
        "\n",
        "# KMeans\n",
        "print(\"\\nHousehold Size Distribution Summary per KMeans Cluster:\")\n",
        "hhsize_kmeans = household_features.groupby('kmeans_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_kmeans)\n",
        "\n",
        "# Agglomerative\n",
        "print(\"\\nHousehold Size Distribution Summary per Agglomerative Cluster:\")\n",
        "hhsize_agglo = household_features.groupby('agglo_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_agglo)\n",
        "\n",
        "# DBSCAN (Excluding noise)\n",
        "print(\"\\nHousehold Size Distribution Summary per DBSCAN Cluster (Excluding Noise):\")\n",
        "if not dbscan_core_clusters.empty:\n",
        "    hhsize_dbscan = dbscan_core_clusters.groupby('dbscan_cluster')['hhsize_decoded'].describe()\n",
        "    display(hhsize_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for household size analysis.\")\n",
        "\n",
        "# KMeans PCA\n",
        "print(\"\\nHousehold Size Distribution Summary per KMeans PCA Cluster:\")\n",
        "hhsize_kmeans_pca = household_features.groupby('kmeans_pca_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_kmeans_pca)\n",
        "\n",
        "# Agglomerative PCA\n",
        "print(\"\\nHousehold Size Distribution Summary per Agglomerative PCA Cluster:\")\n",
        "hhsize_agglo_pca = household_features.groupby('agglo_pca_cluster')['hhsize_decoded'].describe()\n",
        "display(hhsize_agglo_pca)\n",
        "\n",
        "# DBSCAN PCA (Excluding noise)\n",
        "print(\"\\nHousehold Size Distribution Summary per DBSCAN PCA Cluster (Excluding Noise):\")\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    hhsize_dbscan_pca = dbscan_pca_core_clusters.groupby('dbscan_pca_cluster')['hhsize_decoded'].describe()\n",
        "    display(hhsize_dbscan_pca)\n",
        "else:\n",
        "     print(\"No core clusters found in DBSCAN (with PCA) results for household size analysis.\")\n",
        "\n",
        "\n",
        "# Household Income Analysis\n",
        "print(\"\\nHousehold Income (hhincome_decoded) Analysis per Cluster\")\n",
        "\n",
        "# KMeans\n",
        "print(\"\\nCluster proportion across Household Income Categories (KMeans):\")\n",
        "income_kmeans = pd.crosstab(household_features['kmeans_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_kmeans)\n",
        "\n",
        "# Agglomerative\n",
        "print(\"\\nCluster proportion across Household Income Categories (Agglomerative):\")\n",
        "income_agglo = pd.crosstab(household_features['agglo_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_agglo)\n",
        "\n",
        "# DBSCAN (Excluding noise)\n",
        "print(\"\\nCluster proportion across Household Income Categories (DBSCAN - Core Clusters):\")\n",
        "if not dbscan_core_clusters.empty:\n",
        "    income_dbscan = pd.crosstab(dbscan_core_clusters['dbscan_cluster'], dbscan_core_clusters['hhincome_decoded'], normalize='index')\n",
        "    display(income_dbscan)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN results (without PCA) for income analysis.\")\n",
        "\n",
        "\n",
        "# KMeans PCA\n",
        "print(\"\\nCluster proportion across Household Income Categories (KMeans PCA):\")\n",
        "income_kmeans_pca = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_kmeans_pca)\n",
        "\n",
        "# Agglomerative PCA\n",
        "print(\"\\nCluster proportion across Household Income Categories (Agglomerative PCA):\")\n",
        "income_agglo_pca = pd.crosstab(household_features['agglo_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "display(income_agglo_pca)\n",
        "\n",
        "# DBSCAN PCA (Excluding noise)\n",
        "print(\"\\nCluster proportion across Household Income Categories (DBSCAN PCA - Core Clusters):\")\n",
        "if not dbscan_pca_core_clusters.empty:\n",
        "    income_dbscan_pca = pd.crosstab(dbscan_pca_core_clusters['dbscan_pca_cluster'], dbscan_pca_core_clusters['hhincome_decoded'], normalize='index')\n",
        "    display(income_dbscan_pca)\n",
        "else:\n",
        "    print(\"No core clusters found in DBSCAN (with PCA) results for income analysis.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe16f835"
      },
      "source": [
        "# Display the mean feature values per KMeans PCA cluster\n",
        "# This table was generated during the analysis phase (cell id: f4c3a34f, also recreated in LMBgg9j_XcF7)\n",
        "# Recreate the analysis_features list if it's not available in this session\n",
        "if 'analysis_features' not in locals():\n",
        "    analysis_features = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\"] + [col for col in household_features.columns if col.startswith(\"owns_\")]\n",
        "\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[analysis_features].mean()\n",
        "display(kmeans_pca_cluster_analysis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acca9a1c"
      },
      "source": [
        "# Display the mean feature values per KMeans PCA cluster\n",
        "# This table was generated during the analysis phase (cell id: f4c3a34f, also recreated in LMBgg9j_XcF7)\n",
        "# Recreate the analysis_features list if it's not available in this session\n",
        "if 'analysis_features' not in locals():\n",
        "    analysis_features = [\"total_usage_hours\", \"unique_appliance_count\", \"total_appliance_instances\"] + [col for col in household_features.columns if col.startswith(\"owns_\")]\n",
        "\n",
        "kmeans_pca_cluster_analysis = household_features.groupby('kmeans_pca_cluster')[analysis_features].mean()\n",
        "display(kmeans_pca_cluster_analysis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5024d4e6"
      },
      "source": [
        "# Display the geographic distribution of KMeans PCA clusters\n",
        "# These tables were generated during the analysis phase (cell id: jR7seXqx-Zff)\n",
        "# Recreate geographic analysis variables if not available\n",
        "if 'cluster_zone_prop' not in locals() or 'cluster_state_prop' not in locals() or 'cluster_lga' not in locals():\n",
        "    cluster_zone_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['zone'], normalize='index')\n",
        "    cluster_state_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['state'], normalize='index')\n",
        "    cluster_lga = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['lga'])\n",
        "\n",
        "print(\"Cluster proportion across Zones:\")\n",
        "display(cluster_zone_prop)\n",
        "\n",
        "print(\"\\nCluster proportion across States:\")\n",
        "display(cluster_state_prop)\n",
        "\n",
        "print(\"\\nCluster distribution across LGAs (Counts):\")\n",
        "display(cluster_lga)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a745554"
      },
      "source": [
        "# Display the household size distribution summary per KMeans PCA cluster\n",
        "# This table and plot were generated during the analysis phase (cell id: 13FefYGJ-40r)\n",
        "# Recreate hhsize_analysis variable if not available\n",
        "if 'hhsize_analysis' not in locals():\n",
        "    hhsize_analysis = household_features.groupby('kmeans_pca_cluster')['hhsize_decoded'].describe()\n",
        "\n",
        "print(\"\\nHousehold Size Distribution Summary per Cluster:\")\n",
        "display(hhsize_analysis)\n",
        "\n",
        "# Replot the box plot for household size distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='kmeans_pca_cluster', y='hhsize_decoded', data=household_features)\n",
        "plt.title('Household Size Distribution per KMeans PCA Cluster')\n",
        "plt.xlabel('KMeans PCA Cluster')\n",
        "plt.ylabel('Household Size (hhsize_decoded)')\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83aaa31d"
      },
      "source": [
        "# Display the household income distribution per KMeans PCA cluster\n",
        "# These tables were generated during the analysis phase (cell id: c143b78f)\n",
        "# Recreate cluster_income_prop variable if not available\n",
        "if 'cluster_income_prop' not in locals():\n",
        "    cluster_income_prop = pd.crosstab(household_features['kmeans_pca_cluster'], household_features['hhincome_decoded'], normalize='index')\n",
        "\n",
        "print(\"\\nCluster proportion across Household Income Categories (Proportions within each cluster):\")\n",
        "display(cluster_income_prop)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}